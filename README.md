# Saber: Scaling Zero-Shot Reference-to-Video Generation

Zijian Zhou<sup>1,2</sup>, Shikun Liu<sup>1</sup>, Haozhe Liu<sup>1</sup>, Haonan Qiu<sup>1</sup>, Zhaochong An<sup>1</sup>, Weiming Ren<sup>1</sup>, Zhiheng Liu<sup>1</sup>, Xiaoke Huang<sup>1</sup>, Kam Woh Ng<sup>1</sup>, Tian Xie<sup>1</sup>, Xiao Han<sup>1</sup>, Yuren Cong<sup>1</sup>, Hang Li<sup>1</sup>, Chuyan Zhu<sup>1</sup>, Aditya Patel<sup>1</sup>, Tao Xiang<sup>1</sup>, Sen He<sup>1</sup>

<sup>1</sup> Meta AI &nbsp;&nbsp;&nbsp; <sup>2</sup> King's College London


**The training and inference code will be released once it has been organized. Please stay tuned.**


## Project Overview

**Saber** is a scalable zero-shot framework for reference-to-video (R2V) generation. By introducing a masked training strategy, Saber bypasses the bottleneck of explicit reference image-video-text triplet datasets, training exclusively on video-text pairs to achieve zero-shot generation capabilities without explicit R2V data.

## Citation

If you find Saber useful for your research, please cite our paper:

```bibtex
@article{zhou2025scaling,
    title={Scaling Zero-Shot Reference-to-Video Generation},
    author={Zhou, Zijian and Liu, Shikun and Liu, Haozhe and Qiu, Haonan and An, Zhaochong and Ren, Weiming and Liu, Zhiheng and Huang, Xiaoke and Ng, Kam Woh and Xie, Tian and Han, Xiao and Cong, Yuren and Li, Hang and Zhu, Chuyan and Patel, Aditya and Xiang, Tao and He, Sen},
    journal={arXiv preprint arXiv:2512.06905},
    year={2025}
}
```
